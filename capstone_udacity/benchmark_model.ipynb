{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy import sparse\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_features = sparse.load_npz(\"temp_res/train_features.npz\")\n",
    "test_features = sparse.load_npz(\"temp_res/test_features.npz\")\n",
    "test = pd.read_csv('data/test.csv').fillna(' ')[:test_features.shape[0]]\n",
    "train = pd.read_csv('data/train.csv').fillna(' ')[:train_features.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 26.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9798134326926518\n",
      "best params are:\n",
      "{'C': 1, 'max_iter': 200, 'solver': 'sag', 'tol': 0.01}\n",
      "<class 'numpy.ndarray'>\n",
      "(153164, 2)\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 35.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class severe_toxic is 0.9891195702371048\n",
      "best params are:\n",
      "{'C': 1, 'max_iter': 200, 'solver': 'sag', 'tol': 0.001}\n",
      "<class 'numpy.ndarray'>\n",
      "(153164, 2)\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 27.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class obscene is 0.9906336983821018\n",
      "best params are:\n",
      "{'C': 1, 'max_iter': 200, 'solver': 'sag', 'tol': 0.001}\n",
      "<class 'numpy.ndarray'>\n",
      "(153164, 2)\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 39.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class threat is 0.9906024809967433\n",
      "best params are:\n",
      "{'C': 5, 'max_iter': 200, 'solver': 'sag', 'tol': 0.01}\n",
      "<class 'numpy.ndarray'>\n",
      "(153164, 2)\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 31.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class insult is 0.9824663797255095\n",
      "best params are:\n",
      "{'C': 1, 'max_iter': 200, 'solver': 'sag', 'tol': 0.01}\n",
      "<class 'numpy.ndarray'>\n",
      "(153164, 2)\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 35.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class identity_hate is 0.9859580174845588\n",
      "best params are:\n",
      "{'C': 1, 'max_iter': 200, 'solver': 'sag', 'tol': 0.0001}\n",
      "<class 'numpy.ndarray'>\n",
      "(153164, 2)\n",
      "Total CV score is 0.9864322632531116\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"begin training\")\n",
    "    scores = []\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for class_name in class_names:\n",
    "        train_target = train[class_name]\n",
    "        clf = LogisticRegression(random_state=0)\n",
    "        cv_sets = ShuffleSplit(n_splits=3, test_size=0.20, random_state=0)\n",
    "        parameters = {\n",
    "            \"C\": [0.1, 1, 5],\n",
    "            \"tol\": [1e-3, 1e-4, 1e-2],\n",
    "            \"solver\": [\"sag\", \"saga\"],\n",
    "            \"max_iter\": [200]\n",
    "        }\n",
    "        grid = GridSearchCV(clf, param_grid=parameters, scoring='roc_auc', cv=cv_sets, verbose=10, n_jobs=2)\n",
    "\n",
    "        grid = grid.fit(train_features, train_target)\n",
    "        best_clf = grid.best_estimator_\n",
    "        scores.append(grid.best_score_)\n",
    "        print('CV score for class {} is {}'.format(class_name, grid.best_score_))\n",
    "        print(\"best params are:\")\n",
    "        print(grid.best_params_)\n",
    "        best_clf.fit(train_features, train_target)\n",
    "        res = best_clf.predict_proba(test_features)\n",
    "        print(type(res))\n",
    "        print(res.shape)\n",
    "        submission[class_name] = best_clf.predict_proba(test_features)[:, 1]\n",
    "    print('Total CV score is {}'.format(np.mean(scores)))\n",
    "    submission.to_csv('subm/bench_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
